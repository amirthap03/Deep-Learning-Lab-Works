{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lejuXJc6XJBM",
        "outputId": "2766a39c-c938-47a1-9c75-78f99c30f951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5523 - accuracy: 0.7500\n",
            "Loss: 0.5522702932357788, Accuracy: 0.75\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Predictions:\n",
            "Input: [0. 0.], Predicted: 0.58\n",
            "Input: [0. 1.], Predicted: 0.58\n",
            "Input: [1. 0.], Predicted: 0.58\n",
            "Input: [1. 1.], Predicted: 0.22\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define the XOR input data and labels\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(2, input_dim=2, activation='relu'),  # Hidden layer with 2 units and ReLU activation\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 unit and sigmoid activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_data, y_data, epochs=1000, verbose=0)  # You can adjust the number of epochs as needed\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_data, y_data)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_data)\n",
        "print(\"Predictions:\")\n",
        "for i, x in enumerate(x_data):\n",
        "    print(f\"Input: {x}, Predicted: {predictions[i][0]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset (replace with your character dataset)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # Change 10 to the number of character classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data (assuming grayscale images)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, num_classes=10)  # Change 10 to the number of character classes\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64)  # Adjust the number of epochs and batch size\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIMg9REEXhFK",
        "outputId": "505edf77-122b-422a-850c-0dd9d005dd5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 45s 47ms/step - loss: 0.1832 - accuracy: 0.9429\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.0521 - accuracy: 0.9837\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0367 - accuracy: 0.9884\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 45s 48ms/step - loss: 0.0287 - accuracy: 0.9911\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 44s 47ms/step - loss: 0.0223 - accuracy: 0.9928\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0544 - accuracy: 0.9838\n",
            "Test accuracy: 0.9837999939918518\n",
            "313/313 [==============================] - 2s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define constants\n",
        "input_shape = (224, 224, 3)  # Adjust the input size according to your dataset\n",
        "num_classes = 3  # Replace with the number of individuals/classes to recognize\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Load a pre-trained VGGFace model (VGG16-based)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a custom top classifier for face recognition\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare the data (replace with your dataset)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Load your training data and labels\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/pig',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('face_recognition_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzwvbFuCYxLN",
        "outputId": "02afea8a-64ec-4f8e-835f-b76b1a9c5d99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 9.0861 - accuracy: 0.3750\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 115.6077 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 109.9589 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 33.7173 - accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 5.3722e-05 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 7.6635 - accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 14.9485 - accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.7128 - accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 18.1320 - accuracy: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample text data (you should replace this with your dataset)\n",
        "text_data = [\n",
        "    \"This is an example of a language model.\",\n",
        "    \"Language modeling is important for NLP tasks.\",\n",
        "    \"RNNs are commonly used for language modeling.\",\n",
        "    \"You can create powerful models using TensorFlow.\"\n",
        "]\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences and labels\n",
        "input_sequences = []\n",
        "for line in text_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Split sequences into inputs and labels\n",
        "input_sequences = tf.constant(input_sequences)\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# Build the RNN-based language model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the language model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Generate text using the trained model\n",
        "seed_text = \"Language modeling is\"\n",
        "next_words = 5\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "    predicted = model.predict(token_list)\n",
        "    predicted_word_index = tf.argmax(predicted, axis=-1).numpy()[0]\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(seed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9NLN8hBeCb3",
        "outputId": "94bc0109-0f41-4fc8-f969-4325ee5719de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.2206\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.2149\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2092\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2033\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1973\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.1910\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1843\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1771\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1693\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1608\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1514\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1411\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1296\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1168\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1024\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0863\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0681\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.0479\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0254\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.0008\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9748\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9485\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9240\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.9039\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8890\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8755\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8576\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8333\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8044\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7741\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7446\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7163\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6880\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6579\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6244\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5866\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5446\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4989\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4505\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3999\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3466\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2901\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2306\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1689\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1059\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0419\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9783\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9164\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8536\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7893\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7289\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6713\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6124\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5570\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5022\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4498\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3985\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3487\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.3012\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2535\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2072\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1635\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1222\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0832\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0467\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0128\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9788\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9449\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.9130\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8844\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8563\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8295\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8046\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7795\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7559\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7364\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7197\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7008\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6774\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6612\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6458\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6263\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6128\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5996\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5825\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5702\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5583\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5438\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5334\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5229\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5100\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5004\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4904\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4792\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4707\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4618\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4519\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4440\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4360\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4270\n",
            "1/1 [==============================] - 0s 423ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Language modeling is important for nlp tasks tasks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEbJykG6ezXw",
        "outputId": "68db9a8c-c480-4c9b-f664-569359de4c6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data and corrected corresponding labels (0 for negative, 1 for positive)\n",
        "text_data = [\n",
        "    \"I love this product!\",\n",
        "    \"This is great. Highly recommended.\",\n",
        "    \"Terrible experience. Never buying again.\",\n",
        "    \"The service was average.\",\n",
        "]\n",
        "\n",
        "# Corrected labels: 0 for negative, 1 for positive\n",
        "labels = [1, 1, 0, 0]\n",
        "\n",
        "# Tokenize the text data\n",
        "max_words = 1000  # Maximum number of words to keep in the vocabulary\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "\n",
        "# Convert text to sequences and pad them\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Define the LSTM-based sentiment analysis model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Train the model\n",
        "model.fit(sequences, labels, epochs=10, verbose=1)\n",
        "\n",
        "# Evaluate the model on new text data\n",
        "test_data = [\n",
        "    \"This is a good movie.\",\n",
        "    \"I'm not happy with this product.\",\n",
        "    \"I can't believe how bad this service is.\",\n",
        "]\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "predictions = model.predict(test_sequences)\n",
        "for i, text in enumerate(test_data):\n",
        "    sentiment = \"positive\" if predictions[i] > 0.5 else \"negative\"\n",
        "    print(f\"'{text}' has a {sentiment} sentiment.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQB5FkXSeHc-",
        "outputId": "50415660-083c-47a2-e4f8-2186cfab593c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6850 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6775 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6695 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6605 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6503 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6385 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6247 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6086 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5897 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 321 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b57169d32e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 398ms/step\n",
            "'This is a good movie.' has a positive sentiment.\n",
            "'I'm not happy with this product.' has a positive sentiment.\n",
            "'I can't believe how bad this service is.' has a positive sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "import numpy as np\n",
        "\n",
        "# Sample data for parts of speech tagging\n",
        "sentences = [\"I love natural language processing\", \"Parts of speech tagging is important\"]\n",
        "tags = [\"PRON VERB ADJ NOUN NOUN\", \"NOUN ADP NOUN NOUN ADJ\"]\n",
        "\n",
        "# Create vocabulary for words and tags\n",
        "word_vocab = set(\" \".join(sentences).split())\n",
        "tag_vocab = set(\" \".join(tags).split())\n",
        "\n",
        "word_vocab_size = len(word_vocab)\n",
        "tag_vocab_size = len(tag_vocab)\n",
        "\n",
        "# Create word and tag dictionaries for mapping between words/tags and their indices\n",
        "word2idx = {word: idx for idx, word in enumerate(word_vocab)}\n",
        "idx2word = {idx: word for word, idx in enumerate(word_vocab)}\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(tag_vocab)}\n",
        "idx2tag = {idx: tag for tag, idx in enumerate(tag_vocab)}\n",
        "\n",
        "# Convert text data to numerical sequences\n",
        "input_sequences = [[word2idx[word] for word in sentence.split()] for sentence in sentences]\n",
        "target_sequences = [[tag2idx[tag] for tag in tag_sequence.split()] for tag_sequence in tags]\n",
        "\n",
        "# Find the maximum sequence length\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences + target_sequences)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, padding='post', maxlen=max_sequence_length)\n",
        "target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, padding='post', maxlen=max_sequence_length)\n",
        "\n",
        "# Define the Seq2Seq model\n",
        "input_layer = Input(shape=(max_sequence_length,))\n",
        "embedding_layer = Embedding(input_dim=word_vocab_size, output_dim=128)(input_layer)\n",
        "encoder = LSTM(128, return_sequences=True)(embedding_layer)\n",
        "decoder = Dense(tag_vocab_size, activation='softmax')(encoder)\n",
        "\n",
        "model = Model(input_layer, decoder)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(input_sequences, target_sequences, epochs=10)\n",
        "\n",
        "# Perform parts of speech tagging on new text\n",
        "new_text = \"Seq2Seq models are versatile tools for NLP tasks\"\n",
        "new_text_sequence = [word2idx.get(word, 0) for word in new_text.split()]\n",
        "new_text_sequence = tf.keras.preprocessing.sequence.pad_sequences([new_text_sequence], padding='post', maxlen=max_sequence_length)\n",
        "\n",
        "predicted_tags = model.predict(new_text_sequence)\n",
        "predicted_tags = [idx2tag.get(idx, 'UNKNOWN') for idx in np.argmax(predicted_tags, axis=-1)[0]]\n",
        "\n",
        "print(f\"Text: {new_text}\")\n",
        "print(f\"Predicted Tags: {' '.join(predicted_tags)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BzcPIrxea1u",
        "outputId": "3aea1a61-c225-453e-872e-afa1b326bbbc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.6100 - accuracy: 0.0833\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6008 - accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5916 - accuracy: 0.5833\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5823 - accuracy: 0.5833\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5726 - accuracy: 0.5833\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.5624 - accuracy: 0.5833\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5516 - accuracy: 0.5833\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.5399 - accuracy: 0.5833\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5273 - accuracy: 0.5833\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5134 - accuracy: 0.5833\n",
            "1/1 [==============================] - 1s 662ms/step\n",
            "Text: Seq2Seq models are versatile tools for NLP tasks\n",
            "Predicted Tags: UNKNOWN UNKNOWN UNKNOWN UNKNOWN UNKNOWN UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load a GAN-generated image (replace with your own GAN model)\n",
        "gan_generated_image = cv2.imread('gan_generated_image.png')\n",
        "\n",
        "# Define a list of augmentation functions\n",
        "augmentation_functions = [\n",
        "    cv2.flip,  # Horizontal flip\n",
        "    cv2.rotate,  # Rotation\n",
        "    cv2.GaussianBlur,  # Gaussian blur\n",
        "    cv2.cvtColor  # Change color space (e.g., from BGR to grayscale)\n",
        "]\n",
        "\n",
        "# Apply random augmentations to the GAN-generated image\n",
        "for augmentation_function in augmentation_functions:\n",
        "    if augmentation_function == cv2.flip:\n",
        "        augmented_image = augmentation_function(gan_generated_image, 1)  # Horizontal flip\n",
        "    elif augmentation_function == cv2.rotate:\n",
        "        augmented_image = augmentation_function(gan_generated_image, cv2.ROTATE_90_CLOCKWISE)  # Rotation\n",
        "    elif augmentation_function == cv2.GaussianBlur:\n",
        "        augmented_image = augmentation_function(gan_generated_image, (5, 5), 0)  # Gaussian blur\n",
        "    elif augmentation_function == cv2.cvtColor:\n",
        "        augmented_image = augmentation_function(gan_generated_image, cv2.COLOR_BGR2GRAY)  # Change color space\n",
        "\n",
        "    # Save the augmented image with a descriptive filename\n",
        "    filename = f'augmented_{augmentation_function.__name__}.png'\n",
        "    cv2.imwrite(filename, augmented_image)\n",
        "\n",
        "# You can further customize the augmentations by adjusting parameters or adding more functions.\n"
      ],
      "metadata": {
        "id": "tOciaa0wh9f6"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}